{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task3_train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J51OlO1wmsoN",
        "YlB35usKrFGH",
        "BPF8wtgJstH9"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AIkPNxmi_LU"
      },
      "source": [
        "# **Read Images**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZD22_agadqS"
      },
      "source": [
        "# reference: \"https://github.com/kulikovv/DeepColoring\"\n",
        "\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_3Uy-5TazgN"
      },
      "source": [
        "path = \"drive/My Drive/COMP9517/ALL/train\"\n",
        "imagesName = sorted([join(path,fn) for fn in listdir(path)])  # a list saving images name --> str list"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue2cmotwkr0a"
      },
      "source": [
        "images = [cv2.cvtColor(cv2.imread(fn), cv2.COLOR_BGR2RGB) for fn in imagesName if fn.endswith(\"rgb.png\")] # a list saving RGB --> np float32 list"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFRC6Jvbmtut"
      },
      "source": [
        "labels = [cv2.cvtColor(cv2.imread(fn), cv2.COLOR_BGR2GRAY) for fn in imagesName if fn.endswith(\"label.png\")] # a list saving labels --> np float32 list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J51OlO1wmsoN"
      },
      "source": [
        "# **Pre-Process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUgvgAH0mAdE"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.transform import SimilarityTransform as st\n",
        "import skimage.transform as transform\n",
        "from skimage.filters import gaussian\n",
        "from skimage.transform import warp\n",
        "\n",
        "pre_process = []"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPT2zZEVmUO5"
      },
      "source": [
        "#digitizeï¼šonly labels need\n",
        "def digitize(array, is_rgb):\n",
        "    dst = array\n",
        "    if not is_rgb:\n",
        "        dst = np.digitize(array,bins=np.unique(array))-1\n",
        "    return dst\n",
        "pre_process.append(digitize)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSB8XVHNmUQ5"
      },
      "source": [
        "#trandform_type rgb.astype(np.float32), label.astype(np.int32)\n",
        "def trandform_type(array, is_rgb):\n",
        "    if is_rgb:\n",
        "        dst = array.astype(\"float32\")\n",
        "    else:\n",
        "        dst = array.astype(\"int32\")\n",
        "    return dst\n",
        "pre_process.append(trandform_type)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEXN-W2E0nNl"
      },
      "source": [
        "#clip the image to shape(192,192)\n",
        "def get_part_random(array, is_rgb):\n",
        "    cx = np.random.randint(0, array.shape[0] - 192)\n",
        "    cy = np.random.randint(0, array.shape[1] - 192)\n",
        "    return array[cx:cx+192, cy:cy+192]\n",
        "pre_process.append(get_part_random)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM2pXhQH0nNp"
      },
      "source": [
        "def flip_way1(array, is_rgb):\n",
        "    dst = array\n",
        "    if np.random.random() < 0.5:\n",
        "        dst = cv2.flip(array, 1)\n",
        "    return dst\n",
        "pre_process.append(flip_way1)\n",
        "\n",
        "def flip_way2(array, is_rgb):\n",
        "    dst = array\n",
        "    if np.random.random() < 0.5:\n",
        "        dst = cv2.flip(array, 0)\n",
        "    return dst\n",
        "pre_process.append(flip_way2)\n",
        "\n",
        "def rotate90(array, is_rgb):\n",
        "    dst = array\n",
        "    if np.random.random() < 0.5:\n",
        "        dst = np.rot90(array, 2, axes=(0, 1)) \n",
        "    return dst\n",
        "pre_process.append(rotate90)\n",
        "\n",
        "def gaussian_blur(array, is_rgb):\n",
        "    dst = array\n",
        "    if is_rgb:\n",
        "        if np.random.random() < 0.5:\n",
        "            dst = gaussian(array, sigma=abs(1. + 0.1 * np.random.randn()),preserve_range=True,multichannel=True)\n",
        "    return dst\n",
        "pre_process.append(gaussian_blur)\n",
        "\n",
        "def multiple_transform(array, is_rgb):\n",
        "    scalex = scaley = 1. + np.random.randn() * 0.1\n",
        "    shift_y, shift_x = np.array(array.shape[:2]) / 2.\n",
        "    shift = st(translation=[-shift_x, -shift_y])\n",
        "    shift_inv = st(translation=[shift_x + np.random.randn() * 0., shift_y + np.random.randn() * 0.])\n",
        "    trans = st(rotation=np.deg2rad(np.random.uniform(-90, 90)), scale=(scalex, scaley))\n",
        "    final_transform = (shift + (trans + shift_inv)).inverse\n",
        "    \n",
        "    dst = warp(array, final_transform, mode='constant', order=0, cval=0, preserve_range=True)\n",
        "    if is_rgb:\n",
        "        dst = warp(array, final_transform, mode='reflect', order=1, cval=0, preserve_range=True)\n",
        "    return dst\n",
        "pre_process.append(multiple_transform)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCjYu0fWmUS4"
      },
      "source": [
        "\"\"\" normalization \"\"\"\n",
        "def normalization(array, is_rgb):\n",
        "    dst = array\n",
        "    if is_rgb:\n",
        "      dst = (dst - 0.5) / 0.5\n",
        "    return dst\n",
        "\n",
        "pre_process.append(normalization)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlB35usKrFGH"
      },
      "source": [
        "# **Nerual Network (Unet)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlVcr97ymUU8"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LXeFfNhmUWy"
      },
      "source": [
        "class unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(unet,self).__init__()\n",
        "        # input image\n",
        "        self.inputLayer = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # down layers\n",
        "        self.downLayer1 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.downLayer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.downLayer3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # up layers\n",
        "        self.upLayer3_1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.upLayer3_2 = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.upLayer2_1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.upLayer2_2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.upLayer1_1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.upLayer1_2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # output layer\n",
        "        self.outputLayer = nn.Conv2d(32, 9, kernel_size=1, stride=1)\n",
        "\n",
        "        # combine\n",
        "\n",
        "    def forward(self,image):\n",
        "        input = self.inputLayer(image)\n",
        "\n",
        "        # down\n",
        "        down1 = self.downLayer1(input)\n",
        "        down2 = self.downLayer2(down1)\n",
        "        down3 = self.downLayer3(down2)\n",
        "\n",
        "        # up\n",
        "        up3_0 = self.upLayer3_1(down3)\n",
        "        up3_1 = torch.cat([up3_0, down2], dim=1)\n",
        "        up3 = self.upLayer3_2(up3_1)\n",
        "\n",
        "        up2_0 = self.upLayer2_1(up3)\n",
        "        up2_1 = torch.cat([up2_0, down1], dim=1)\n",
        "        up2 = self.upLayer2_2(up2_1)\n",
        "\n",
        "        up1_0 = self.upLayer1_1(up2)\n",
        "        up1_1 = torch.cat([up1_0, input], dim=1)\n",
        "        up1 = self.upLayer1_2(up1_1)\n",
        "\n",
        "        # output\n",
        "        output = self.outputLayer(up1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPF8wtgJstH9"
      },
      "source": [
        "# **Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5VBibUAssKK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxIPgd-jmUY1"
      },
      "source": [
        "class HaloLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(HaloLoss,self).__init__()\n",
        "  \n",
        "  def forward(self, ypred, label):\n",
        "    max_leaves = 30   # assume the maximum number of leaves\n",
        "    k = np.array([[0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0], # a halo kernel\n",
        "            [0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0],\n",
        "            [0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],\n",
        "            [0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],\n",
        "            [0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],\n",
        "            [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "            [0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],\n",
        "            [0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],\n",
        "            [0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],\n",
        "            [0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0]], dtype='float32')\n",
        "    k_muti = np.expand_dims(np.expand_dims(k, 0), 0)\n",
        "    kernel = np.vstack([k_muti]*max_leaves)\n",
        "    kernel = torch.from_numpy(kernel).to(device)\n",
        "\n",
        "    \n",
        "    # split the leaves\n",
        "    min_area = 10 # assume the area of leaf is less than it, then it is noise\n",
        "    codeOfLeaves = []\n",
        "    eachLeaf = np.zeros((label.shape[0], max_leaves, label.shape[1], label.shape[2]))\n",
        "\n",
        "    for i in range(label.shape[0]):\n",
        "      area = np.bincount(label[i].flatten())\n",
        "      leaves = np.where(area > min_area)[0] # array: code of leaves and background\n",
        "      max_index = 0\n",
        "      for index, code in enumerate(leaves):\n",
        "        # try:\n",
        "          eachLeaf[i, index, label[i]==code] = float(1)\n",
        "          max_index = index\n",
        "        # except:\n",
        "        #   print(i, len(eachLeaf), len(leaves))\n",
        "        #   import sys\n",
        "        #   sys.exit(1)\n",
        "      leavesCode = [j for j in range(max_index + 1)]\n",
        "      codeOfLeaves.append(np.array(leavesCode))\n",
        "    eachLeaf =  torch.from_numpy(eachLeaf).float().to(device) # split the leaves\n",
        "    \n",
        "    # make a mask\n",
        "    halo = F.conv2d(eachLeaf, kernel, groups=max_leaves, padding=int(k.shape[0]/2)) # create a halo mask\n",
        "    halo[halo > 0] = float(1)     # halo mask = 1\n",
        "    \n",
        "    halo[eachLeaf > 0] = float(2)   # leaves = 2\n",
        "    halo[:, 0, :, :] = float(1)   # backgound = 1\n",
        "    \n",
        "    halo_mask = halo.sum(3 ,keepdim=True)\n",
        "    halo_mask = halo_mask.sum(2, keepdim=True)\n",
        "    halo_mask[halo_mask == 0] = 1\n",
        "    halo = halo / halo_mask\n",
        "\n",
        "    # calculate loss\n",
        "    y_log = F.log_softmax(ypred, dim=1).float()\n",
        "    y_soft = F.softmax(ypred, dim=1).float()\n",
        "    lossValue = torch.tensor([0]).float().to(device)  # initial a loss = 0\n",
        "    \n",
        "    for i in range(ypred.shape[0]):\n",
        "      background = halo[i, 0] * eachLeaf[i, 0]\n",
        "      lossValue -= torch.sum(background * y_log[i, 0]) / torch.sum(background)\n",
        "            \n",
        "      if len(codeOfLeaves[i]) == 1: # only backgound, no leaves\n",
        "        continue\n",
        "      index = torch.LongTensor(codeOfLeaves[i][1:]).to(device) # create an index of leaves\n",
        "      valid_leaves = eachLeaf[i].index_select(0, index)\n",
        "      valid_masks = halo[i].index_select(0, index)\n",
        "    \n",
        "      target_pos = valid_leaves * valid_masks\n",
        "      target_neg = (1. - valid_leaves) * valid_masks\n",
        "\n",
        "      positive = -torch.mm(y_log[i,1:].view(y_log[i,1:].shape[0],-1),target_pos.view(target_pos.shape[0],-1).transpose(1,0))/torch.sum(target_pos)\n",
        "      negative = -torch.mm(torch.log(1-y_soft[i, 1:]+1e-12).view(torch.log(1-y_soft[i, 1:]+1e-12).shape[0], -1), \n",
        "                           target_neg.view(target_neg.shape[0],-1).transpose(1,0)) / torch.sum(target_neg)\n",
        "      _, index_ = torch.min(positive + 7 * negative, 0)\n",
        "      lossValue += torch.sum(positive[index_, torch.arange(0, positive.shape[1]).long().to(device)])   \n",
        "    lossValue = lossValue * (1000/(ypred.shape[2] * ypred.shape[3]))\n",
        "    return lossValue"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WyAY2nFuA_U"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMjQV8FCuAO8"
      },
      "source": [
        "from sys import stdout\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelName = 'drive/My Drive/COMP9517/ALL/ALL model C9_'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzrvhXPHuAQv"
      },
      "source": [
        "model = unet().cuda()\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "lossFunc = HaloLoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSyDNXwPuATC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c55be0-907b-40a5-decf-f01d032ad286"
      },
      "source": [
        "\n",
        "epochs = 5000\n",
        "loopSize = 1 \n",
        "batchSize = 30\n",
        "for epoch in range(epochs):\n",
        "  # do preprocess and generate a images and labels list\n",
        "    X, y = [], []\n",
        "    for k in range(loopSize):\n",
        "        r_index = list(range(len(images)))\n",
        "        random.shuffle(r_index)\n",
        "        # print(r_index)\n",
        "        assert len(images) == len(labels)\n",
        "        for i in r_index[:batchSize]:    # traverse all images\n",
        "            ximg = images[i]\n",
        "            ximg = transform.resize(ximg, np.array(ximg.shape[:2]) / 2,   mode='constant')\n",
        "            ylabel = labels[i]\n",
        "            ylabel = cv2.resize(ylabel, (ylabel.shape[0] // 2, ylabel.shape[1] // 2), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "\n",
        "            for approach in pre_process:  # do all preprocess to an image\n",
        "                seed = np.random.randint(0, 2**32-1)\n",
        "                np.random.seed(seed)\n",
        "                ximg = approach(ximg, True)\n",
        "                np.random.seed(seed)\n",
        "                ylabel = approach(ylabel, False)\n",
        "            \n",
        "\n",
        "            ximg = ximg.transpose(2, 0, 1)\n",
        "            ximg = np.expand_dims(ximg, 0)\n",
        "            ylabel = np.expand_dims(ylabel, 0)\n",
        "            y.append(ylabel)\n",
        "            X.append(ximg)\n",
        "    X = np.vstack(X).astype(\"float32\")\n",
        "    y = np.vstack(y).astype(\"int32\")\n",
        "  \n",
        "  # train\n",
        "    Xtrain = torch.from_numpy(X).to(device) # np to tensor\n",
        "    ytrain = torch.from_numpy(y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # print(Xtrain.size(), ytrain.size())\n",
        "    ypred = model(Xtrain)      # get output\n",
        "    loss = lossFunc(ypred, ytrain) # calculate loss value\n",
        "    loss.backward()    # calculate gradients\n",
        "    optimizer.step()   # Minimise the loss according to the gradient.\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        p = epoch/epochs\n",
        "        print(\"process: %.2f%% (%d in %d)\"%(p*100, epoch+1, epochs))\n",
        "\n",
        "    if (epoch+1) in {50, 100, 200, 500, 1000, 2000, 5000}:\n",
        "        torch.save(model.state_dict(), modelName + str(epoch) + '_LZX.t7')\n",
        "        print(\"%s Save successfully.\"%(epoch+1))\n",
        "\n",
        "\n",
        "p = (epoch+1)/epochs\n",
        "print(\"process: %.2f%% (%d in %d)\"%(p*100, epoch+1, epochs))\n",
        "torch.save(model.state_dict(), modelName + str(epochs) + '_LZX.t7')\n",
        "print(\"Save successfully. Finish\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "process: 0.00% (1 in 5000)\n",
            "process: 0.10% (6 in 5000)\n",
            "process: 0.20% (11 in 5000)\n",
            "process: 0.30% (16 in 5000)\n",
            "process: 0.40% (21 in 5000)\n",
            "process: 0.50% (26 in 5000)\n",
            "process: 0.60% (31 in 5000)\n",
            "process: 0.70% (36 in 5000)\n",
            "process: 0.80% (41 in 5000)\n",
            "process: 0.90% (46 in 5000)\n",
            "50 Save successfully.\n",
            "process: 1.00% (51 in 5000)\n",
            "process: 1.10% (56 in 5000)\n",
            "process: 1.20% (61 in 5000)\n",
            "process: 1.30% (66 in 5000)\n",
            "process: 1.40% (71 in 5000)\n",
            "process: 1.50% (76 in 5000)\n",
            "process: 1.60% (81 in 5000)\n",
            "process: 1.70% (86 in 5000)\n",
            "process: 1.80% (91 in 5000)\n",
            "process: 1.90% (96 in 5000)\n",
            "100 Save successfully.\n",
            "process: 2.00% (101 in 5000)\n",
            "process: 2.10% (106 in 5000)\n",
            "process: 2.20% (111 in 5000)\n",
            "process: 2.30% (116 in 5000)\n",
            "process: 2.40% (121 in 5000)\n",
            "process: 2.50% (126 in 5000)\n",
            "process: 2.60% (131 in 5000)\n",
            "process: 2.70% (136 in 5000)\n",
            "process: 2.80% (141 in 5000)\n",
            "process: 2.90% (146 in 5000)\n",
            "process: 3.00% (151 in 5000)\n",
            "process: 3.10% (156 in 5000)\n",
            "process: 3.20% (161 in 5000)\n",
            "process: 3.30% (166 in 5000)\n",
            "process: 3.40% (171 in 5000)\n",
            "process: 3.50% (176 in 5000)\n",
            "process: 3.60% (181 in 5000)\n",
            "process: 3.70% (186 in 5000)\n",
            "process: 3.80% (191 in 5000)\n",
            "process: 3.90% (196 in 5000)\n",
            "200 Save successfully.\n",
            "process: 4.00% (201 in 5000)\n",
            "process: 4.10% (206 in 5000)\n",
            "process: 4.20% (211 in 5000)\n",
            "process: 4.30% (216 in 5000)\n",
            "process: 4.40% (221 in 5000)\n",
            "process: 4.50% (226 in 5000)\n",
            "process: 4.60% (231 in 5000)\n",
            "process: 4.70% (236 in 5000)\n",
            "process: 4.80% (241 in 5000)\n",
            "process: 4.90% (246 in 5000)\n",
            "process: 5.00% (251 in 5000)\n",
            "process: 5.10% (256 in 5000)\n",
            "process: 5.20% (261 in 5000)\n",
            "process: 5.30% (266 in 5000)\n",
            "process: 5.40% (271 in 5000)\n",
            "process: 5.50% (276 in 5000)\n",
            "process: 5.60% (281 in 5000)\n",
            "process: 5.70% (286 in 5000)\n",
            "process: 5.80% (291 in 5000)\n",
            "process: 5.90% (296 in 5000)\n",
            "process: 6.00% (301 in 5000)\n",
            "process: 6.10% (306 in 5000)\n",
            "process: 6.20% (311 in 5000)\n",
            "process: 6.30% (316 in 5000)\n",
            "process: 6.40% (321 in 5000)\n",
            "process: 6.50% (326 in 5000)\n",
            "process: 6.60% (331 in 5000)\n",
            "process: 6.70% (336 in 5000)\n",
            "process: 6.80% (341 in 5000)\n",
            "process: 6.90% (346 in 5000)\n",
            "process: 7.00% (351 in 5000)\n",
            "process: 7.10% (356 in 5000)\n",
            "process: 7.20% (361 in 5000)\n",
            "process: 7.30% (366 in 5000)\n",
            "process: 7.40% (371 in 5000)\n",
            "process: 7.50% (376 in 5000)\n",
            "process: 7.60% (381 in 5000)\n",
            "process: 7.70% (386 in 5000)\n",
            "process: 7.80% (391 in 5000)\n",
            "process: 7.90% (396 in 5000)\n",
            "process: 8.00% (401 in 5000)\n",
            "process: 8.10% (406 in 5000)\n",
            "process: 8.20% (411 in 5000)\n",
            "process: 8.30% (416 in 5000)\n",
            "process: 8.40% (421 in 5000)\n",
            "process: 8.50% (426 in 5000)\n",
            "process: 8.60% (431 in 5000)\n",
            "process: 8.70% (436 in 5000)\n",
            "process: 8.80% (441 in 5000)\n",
            "process: 8.90% (446 in 5000)\n",
            "process: 9.00% (451 in 5000)\n",
            "process: 9.10% (456 in 5000)\n",
            "process: 9.20% (461 in 5000)\n",
            "process: 9.30% (466 in 5000)\n",
            "process: 9.40% (471 in 5000)\n",
            "process: 9.50% (476 in 5000)\n",
            "process: 9.60% (481 in 5000)\n",
            "process: 9.70% (486 in 5000)\n",
            "process: 9.80% (491 in 5000)\n",
            "process: 9.90% (496 in 5000)\n",
            "500 Save successfully.\n",
            "process: 10.00% (501 in 5000)\n",
            "process: 10.10% (506 in 5000)\n",
            "process: 10.20% (511 in 5000)\n",
            "process: 10.30% (516 in 5000)\n",
            "process: 10.40% (521 in 5000)\n",
            "process: 10.50% (526 in 5000)\n",
            "process: 10.60% (531 in 5000)\n",
            "process: 10.70% (536 in 5000)\n",
            "process: 10.80% (541 in 5000)\n",
            "process: 10.90% (546 in 5000)\n",
            "process: 11.00% (551 in 5000)\n",
            "process: 11.10% (556 in 5000)\n",
            "process: 11.20% (561 in 5000)\n",
            "process: 11.30% (566 in 5000)\n",
            "process: 11.40% (571 in 5000)\n",
            "process: 11.50% (576 in 5000)\n",
            "process: 11.60% (581 in 5000)\n",
            "process: 11.70% (586 in 5000)\n",
            "process: 11.80% (591 in 5000)\n",
            "process: 11.90% (596 in 5000)\n",
            "process: 12.00% (601 in 5000)\n",
            "process: 12.10% (606 in 5000)\n",
            "process: 12.20% (611 in 5000)\n",
            "process: 12.30% (616 in 5000)\n",
            "process: 12.40% (621 in 5000)\n",
            "process: 12.50% (626 in 5000)\n",
            "process: 12.60% (631 in 5000)\n",
            "process: 12.70% (636 in 5000)\n",
            "process: 12.80% (641 in 5000)\n",
            "process: 12.90% (646 in 5000)\n",
            "process: 13.00% (651 in 5000)\n",
            "process: 13.10% (656 in 5000)\n",
            "process: 13.20% (661 in 5000)\n",
            "process: 13.30% (666 in 5000)\n",
            "process: 13.40% (671 in 5000)\n",
            "process: 13.50% (676 in 5000)\n",
            "process: 13.60% (681 in 5000)\n",
            "process: 13.70% (686 in 5000)\n",
            "process: 13.80% (691 in 5000)\n",
            "process: 13.90% (696 in 5000)\n",
            "process: 14.00% (701 in 5000)\n",
            "process: 14.10% (706 in 5000)\n",
            "process: 14.20% (711 in 5000)\n",
            "process: 14.30% (716 in 5000)\n",
            "process: 14.40% (721 in 5000)\n",
            "process: 14.50% (726 in 5000)\n",
            "process: 14.60% (731 in 5000)\n",
            "process: 14.70% (736 in 5000)\n",
            "process: 14.80% (741 in 5000)\n",
            "process: 14.90% (746 in 5000)\n",
            "process: 15.00% (751 in 5000)\n",
            "process: 15.10% (756 in 5000)\n",
            "process: 15.20% (761 in 5000)\n",
            "process: 15.30% (766 in 5000)\n",
            "process: 15.40% (771 in 5000)\n",
            "process: 15.50% (776 in 5000)\n",
            "process: 15.60% (781 in 5000)\n",
            "process: 15.70% (786 in 5000)\n",
            "process: 15.80% (791 in 5000)\n",
            "process: 15.90% (796 in 5000)\n",
            "process: 16.00% (801 in 5000)\n",
            "process: 16.10% (806 in 5000)\n",
            "process: 16.20% (811 in 5000)\n",
            "process: 16.30% (816 in 5000)\n",
            "process: 16.40% (821 in 5000)\n",
            "process: 16.50% (826 in 5000)\n",
            "process: 16.60% (831 in 5000)\n",
            "process: 16.70% (836 in 5000)\n",
            "process: 16.80% (841 in 5000)\n",
            "process: 16.90% (846 in 5000)\n",
            "process: 17.00% (851 in 5000)\n",
            "process: 17.10% (856 in 5000)\n",
            "process: 17.20% (861 in 5000)\n",
            "process: 17.30% (866 in 5000)\n",
            "process: 17.40% (871 in 5000)\n",
            "process: 17.50% (876 in 5000)\n",
            "process: 17.60% (881 in 5000)\n",
            "process: 17.70% (886 in 5000)\n",
            "process: 17.80% (891 in 5000)\n",
            "process: 17.90% (896 in 5000)\n",
            "process: 18.00% (901 in 5000)\n",
            "process: 18.10% (906 in 5000)\n",
            "process: 18.20% (911 in 5000)\n",
            "process: 18.30% (916 in 5000)\n",
            "process: 18.40% (921 in 5000)\n",
            "process: 18.50% (926 in 5000)\n",
            "process: 18.60% (931 in 5000)\n",
            "process: 18.70% (936 in 5000)\n",
            "process: 18.80% (941 in 5000)\n",
            "process: 18.90% (946 in 5000)\n",
            "process: 19.00% (951 in 5000)\n",
            "process: 19.10% (956 in 5000)\n",
            "process: 19.20% (961 in 5000)\n",
            "process: 19.30% (966 in 5000)\n",
            "process: 19.40% (971 in 5000)\n",
            "process: 19.50% (976 in 5000)\n",
            "process: 19.60% (981 in 5000)\n",
            "process: 19.70% (986 in 5000)\n",
            "process: 19.80% (991 in 5000)\n",
            "process: 19.90% (996 in 5000)\n",
            "1000 Save successfully.\n",
            "process: 20.00% (1001 in 5000)\n",
            "process: 20.10% (1006 in 5000)\n",
            "process: 20.20% (1011 in 5000)\n",
            "process: 20.30% (1016 in 5000)\n",
            "process: 20.40% (1021 in 5000)\n",
            "process: 20.50% (1026 in 5000)\n",
            "process: 20.60% (1031 in 5000)\n",
            "process: 20.70% (1036 in 5000)\n",
            "process: 20.80% (1041 in 5000)\n",
            "process: 20.90% (1046 in 5000)\n",
            "process: 21.00% (1051 in 5000)\n",
            "process: 21.10% (1056 in 5000)\n",
            "process: 21.20% (1061 in 5000)\n",
            "process: 21.30% (1066 in 5000)\n",
            "process: 21.40% (1071 in 5000)\n",
            "process: 21.50% (1076 in 5000)\n",
            "process: 21.60% (1081 in 5000)\n",
            "process: 21.70% (1086 in 5000)\n",
            "process: 21.80% (1091 in 5000)\n",
            "process: 21.90% (1096 in 5000)\n",
            "process: 22.00% (1101 in 5000)\n",
            "process: 22.10% (1106 in 5000)\n",
            "process: 22.20% (1111 in 5000)\n",
            "process: 22.30% (1116 in 5000)\n",
            "process: 22.40% (1121 in 5000)\n",
            "process: 22.50% (1126 in 5000)\n",
            "process: 22.60% (1131 in 5000)\n",
            "process: 22.70% (1136 in 5000)\n",
            "process: 22.80% (1141 in 5000)\n",
            "process: 22.90% (1146 in 5000)\n",
            "process: 23.00% (1151 in 5000)\n",
            "process: 23.10% (1156 in 5000)\n",
            "process: 23.20% (1161 in 5000)\n",
            "process: 23.30% (1166 in 5000)\n",
            "process: 23.40% (1171 in 5000)\n",
            "process: 23.50% (1176 in 5000)\n",
            "process: 23.60% (1181 in 5000)\n",
            "process: 23.70% (1186 in 5000)\n",
            "process: 23.80% (1191 in 5000)\n",
            "process: 23.90% (1196 in 5000)\n",
            "process: 24.00% (1201 in 5000)\n",
            "process: 24.10% (1206 in 5000)\n",
            "process: 24.20% (1211 in 5000)\n",
            "process: 24.30% (1216 in 5000)\n",
            "process: 24.40% (1221 in 5000)\n",
            "process: 24.50% (1226 in 5000)\n",
            "process: 24.60% (1231 in 5000)\n",
            "process: 24.70% (1236 in 5000)\n",
            "process: 24.80% (1241 in 5000)\n",
            "process: 24.90% (1246 in 5000)\n",
            "process: 25.00% (1251 in 5000)\n",
            "process: 25.10% (1256 in 5000)\n",
            "process: 25.20% (1261 in 5000)\n",
            "process: 25.30% (1266 in 5000)\n",
            "process: 25.40% (1271 in 5000)\n",
            "process: 25.50% (1276 in 5000)\n",
            "process: 25.60% (1281 in 5000)\n",
            "process: 25.70% (1286 in 5000)\n",
            "process: 25.80% (1291 in 5000)\n",
            "process: 25.90% (1296 in 5000)\n",
            "process: 26.00% (1301 in 5000)\n",
            "process: 26.10% (1306 in 5000)\n",
            "process: 26.20% (1311 in 5000)\n",
            "process: 26.30% (1316 in 5000)\n",
            "process: 26.40% (1321 in 5000)\n",
            "process: 26.50% (1326 in 5000)\n",
            "process: 26.60% (1331 in 5000)\n",
            "process: 26.70% (1336 in 5000)\n",
            "process: 26.80% (1341 in 5000)\n",
            "process: 26.90% (1346 in 5000)\n",
            "process: 27.00% (1351 in 5000)\n",
            "process: 27.10% (1356 in 5000)\n",
            "process: 27.20% (1361 in 5000)\n",
            "process: 27.30% (1366 in 5000)\n",
            "process: 27.40% (1371 in 5000)\n",
            "process: 27.50% (1376 in 5000)\n",
            "process: 27.60% (1381 in 5000)\n",
            "process: 27.70% (1386 in 5000)\n",
            "process: 27.80% (1391 in 5000)\n",
            "process: 27.90% (1396 in 5000)\n",
            "process: 28.00% (1401 in 5000)\n",
            "process: 28.10% (1406 in 5000)\n",
            "process: 28.20% (1411 in 5000)\n",
            "process: 28.30% (1416 in 5000)\n",
            "process: 28.40% (1421 in 5000)\n",
            "process: 28.50% (1426 in 5000)\n",
            "process: 28.60% (1431 in 5000)\n",
            "process: 28.70% (1436 in 5000)\n",
            "process: 28.80% (1441 in 5000)\n",
            "process: 28.90% (1446 in 5000)\n",
            "process: 29.00% (1451 in 5000)\n",
            "process: 29.10% (1456 in 5000)\n",
            "process: 29.20% (1461 in 5000)\n",
            "process: 29.30% (1466 in 5000)\n",
            "process: 29.40% (1471 in 5000)\n",
            "process: 29.50% (1476 in 5000)\n",
            "process: 29.60% (1481 in 5000)\n",
            "process: 29.70% (1486 in 5000)\n",
            "process: 29.80% (1491 in 5000)\n",
            "process: 29.90% (1496 in 5000)\n",
            "process: 30.00% (1501 in 5000)\n",
            "process: 30.10% (1506 in 5000)\n",
            "process: 30.20% (1511 in 5000)\n",
            "process: 30.30% (1516 in 5000)\n",
            "process: 30.40% (1521 in 5000)\n",
            "process: 30.50% (1526 in 5000)\n",
            "process: 30.60% (1531 in 5000)\n",
            "process: 30.70% (1536 in 5000)\n",
            "process: 30.80% (1541 in 5000)\n",
            "process: 30.90% (1546 in 5000)\n",
            "process: 31.00% (1551 in 5000)\n",
            "process: 31.10% (1556 in 5000)\n",
            "process: 31.20% (1561 in 5000)\n",
            "process: 31.30% (1566 in 5000)\n",
            "process: 31.40% (1571 in 5000)\n",
            "process: 31.50% (1576 in 5000)\n",
            "process: 31.60% (1581 in 5000)\n",
            "process: 31.70% (1586 in 5000)\n",
            "process: 31.80% (1591 in 5000)\n",
            "process: 31.90% (1596 in 5000)\n",
            "process: 32.00% (1601 in 5000)\n",
            "process: 32.10% (1606 in 5000)\n",
            "process: 32.20% (1611 in 5000)\n",
            "process: 32.30% (1616 in 5000)\n",
            "process: 32.40% (1621 in 5000)\n",
            "process: 32.50% (1626 in 5000)\n",
            "process: 32.60% (1631 in 5000)\n",
            "process: 32.70% (1636 in 5000)\n",
            "process: 32.80% (1641 in 5000)\n",
            "process: 32.90% (1646 in 5000)\n",
            "process: 33.00% (1651 in 5000)\n",
            "process: 33.10% (1656 in 5000)\n",
            "process: 33.20% (1661 in 5000)\n",
            "process: 33.30% (1666 in 5000)\n",
            "process: 33.40% (1671 in 5000)\n",
            "process: 33.50% (1676 in 5000)\n",
            "process: 33.60% (1681 in 5000)\n",
            "process: 33.70% (1686 in 5000)\n",
            "process: 33.80% (1691 in 5000)\n",
            "process: 33.90% (1696 in 5000)\n",
            "process: 34.00% (1701 in 5000)\n",
            "process: 34.10% (1706 in 5000)\n",
            "process: 34.20% (1711 in 5000)\n",
            "process: 34.30% (1716 in 5000)\n",
            "process: 34.40% (1721 in 5000)\n",
            "process: 34.50% (1726 in 5000)\n",
            "process: 34.60% (1731 in 5000)\n",
            "process: 34.70% (1736 in 5000)\n",
            "process: 34.80% (1741 in 5000)\n",
            "process: 34.90% (1746 in 5000)\n",
            "process: 35.00% (1751 in 5000)\n",
            "process: 35.10% (1756 in 5000)\n",
            "process: 35.20% (1761 in 5000)\n",
            "process: 35.30% (1766 in 5000)\n",
            "process: 35.40% (1771 in 5000)\n",
            "process: 35.50% (1776 in 5000)\n",
            "process: 35.60% (1781 in 5000)\n",
            "process: 35.70% (1786 in 5000)\n",
            "process: 35.80% (1791 in 5000)\n",
            "process: 35.90% (1796 in 5000)\n",
            "process: 36.00% (1801 in 5000)\n",
            "process: 36.10% (1806 in 5000)\n",
            "process: 36.20% (1811 in 5000)\n",
            "process: 36.30% (1816 in 5000)\n",
            "process: 36.40% (1821 in 5000)\n",
            "process: 36.50% (1826 in 5000)\n",
            "process: 36.60% (1831 in 5000)\n",
            "process: 36.70% (1836 in 5000)\n",
            "process: 36.80% (1841 in 5000)\n",
            "process: 36.90% (1846 in 5000)\n",
            "process: 37.00% (1851 in 5000)\n",
            "process: 37.10% (1856 in 5000)\n",
            "process: 37.20% (1861 in 5000)\n",
            "process: 37.30% (1866 in 5000)\n",
            "process: 37.40% (1871 in 5000)\n",
            "process: 37.50% (1876 in 5000)\n",
            "process: 37.60% (1881 in 5000)\n",
            "process: 37.70% (1886 in 5000)\n",
            "process: 37.80% (1891 in 5000)\n",
            "process: 37.90% (1896 in 5000)\n",
            "process: 38.00% (1901 in 5000)\n",
            "process: 38.10% (1906 in 5000)\n",
            "process: 38.20% (1911 in 5000)\n",
            "process: 38.30% (1916 in 5000)\n",
            "process: 38.40% (1921 in 5000)\n",
            "process: 38.50% (1926 in 5000)\n",
            "process: 38.60% (1931 in 5000)\n",
            "process: 38.70% (1936 in 5000)\n",
            "process: 38.80% (1941 in 5000)\n",
            "process: 38.90% (1946 in 5000)\n",
            "process: 39.00% (1951 in 5000)\n",
            "process: 39.10% (1956 in 5000)\n",
            "process: 39.20% (1961 in 5000)\n",
            "process: 39.30% (1966 in 5000)\n",
            "process: 39.40% (1971 in 5000)\n",
            "process: 39.50% (1976 in 5000)\n",
            "process: 39.60% (1981 in 5000)\n",
            "process: 39.70% (1986 in 5000)\n",
            "process: 39.80% (1991 in 5000)\n",
            "process: 39.90% (1996 in 5000)\n",
            "2000 Save successfully.\n",
            "process: 40.00% (2001 in 5000)\n",
            "process: 40.10% (2006 in 5000)\n",
            "process: 40.20% (2011 in 5000)\n",
            "process: 40.30% (2016 in 5000)\n",
            "process: 40.40% (2021 in 5000)\n",
            "process: 40.50% (2026 in 5000)\n",
            "process: 40.60% (2031 in 5000)\n",
            "process: 40.70% (2036 in 5000)\n",
            "process: 40.80% (2041 in 5000)\n",
            "process: 40.90% (2046 in 5000)\n",
            "process: 41.00% (2051 in 5000)\n",
            "process: 41.10% (2056 in 5000)\n",
            "process: 41.20% (2061 in 5000)\n",
            "process: 41.30% (2066 in 5000)\n",
            "process: 41.40% (2071 in 5000)\n",
            "process: 41.50% (2076 in 5000)\n",
            "process: 41.60% (2081 in 5000)\n",
            "process: 41.70% (2086 in 5000)\n",
            "process: 41.80% (2091 in 5000)\n",
            "process: 41.90% (2096 in 5000)\n",
            "process: 42.00% (2101 in 5000)\n",
            "process: 42.10% (2106 in 5000)\n",
            "process: 42.20% (2111 in 5000)\n",
            "process: 42.30% (2116 in 5000)\n",
            "process: 42.40% (2121 in 5000)\n",
            "process: 42.50% (2126 in 5000)\n",
            "process: 42.60% (2131 in 5000)\n",
            "process: 42.70% (2136 in 5000)\n",
            "process: 42.80% (2141 in 5000)\n",
            "process: 42.90% (2146 in 5000)\n",
            "process: 43.00% (2151 in 5000)\n",
            "process: 43.10% (2156 in 5000)\n",
            "process: 43.20% (2161 in 5000)\n",
            "process: 43.30% (2166 in 5000)\n",
            "process: 43.40% (2171 in 5000)\n",
            "process: 43.50% (2176 in 5000)\n",
            "process: 43.60% (2181 in 5000)\n",
            "process: 43.70% (2186 in 5000)\n",
            "process: 43.80% (2191 in 5000)\n",
            "process: 43.90% (2196 in 5000)\n",
            "process: 44.00% (2201 in 5000)\n",
            "process: 44.10% (2206 in 5000)\n",
            "process: 44.20% (2211 in 5000)\n",
            "process: 44.30% (2216 in 5000)\n",
            "process: 44.40% (2221 in 5000)\n",
            "process: 44.50% (2226 in 5000)\n",
            "process: 44.60% (2231 in 5000)\n",
            "process: 44.70% (2236 in 5000)\n",
            "process: 44.80% (2241 in 5000)\n",
            "process: 44.90% (2246 in 5000)\n",
            "process: 45.00% (2251 in 5000)\n",
            "process: 45.10% (2256 in 5000)\n",
            "process: 45.20% (2261 in 5000)\n",
            "process: 45.30% (2266 in 5000)\n",
            "process: 45.40% (2271 in 5000)\n",
            "process: 45.50% (2276 in 5000)\n",
            "process: 45.60% (2281 in 5000)\n",
            "process: 45.70% (2286 in 5000)\n",
            "process: 45.80% (2291 in 5000)\n",
            "process: 45.90% (2296 in 5000)\n",
            "process: 46.00% (2301 in 5000)\n",
            "process: 46.10% (2306 in 5000)\n",
            "process: 46.20% (2311 in 5000)\n",
            "process: 46.30% (2316 in 5000)\n",
            "process: 46.40% (2321 in 5000)\n",
            "process: 46.50% (2326 in 5000)\n",
            "process: 46.60% (2331 in 5000)\n",
            "process: 46.70% (2336 in 5000)\n",
            "process: 46.80% (2341 in 5000)\n",
            "process: 46.90% (2346 in 5000)\n",
            "process: 47.00% (2351 in 5000)\n",
            "process: 47.10% (2356 in 5000)\n",
            "process: 47.20% (2361 in 5000)\n",
            "process: 47.30% (2366 in 5000)\n",
            "process: 47.40% (2371 in 5000)\n",
            "process: 47.50% (2376 in 5000)\n",
            "process: 47.60% (2381 in 5000)\n",
            "process: 47.70% (2386 in 5000)\n",
            "process: 47.80% (2391 in 5000)\n",
            "process: 47.90% (2396 in 5000)\n",
            "process: 48.00% (2401 in 5000)\n",
            "process: 48.10% (2406 in 5000)\n",
            "process: 48.20% (2411 in 5000)\n",
            "process: 48.30% (2416 in 5000)\n",
            "process: 48.40% (2421 in 5000)\n",
            "process: 48.50% (2426 in 5000)\n",
            "process: 48.60% (2431 in 5000)\n",
            "process: 48.70% (2436 in 5000)\n",
            "process: 48.80% (2441 in 5000)\n",
            "process: 48.90% (2446 in 5000)\n",
            "process: 49.00% (2451 in 5000)\n",
            "process: 49.10% (2456 in 5000)\n",
            "process: 49.20% (2461 in 5000)\n",
            "process: 49.30% (2466 in 5000)\n",
            "process: 49.40% (2471 in 5000)\n",
            "process: 49.50% (2476 in 5000)\n",
            "process: 49.60% (2481 in 5000)\n",
            "process: 49.70% (2486 in 5000)\n",
            "process: 49.80% (2491 in 5000)\n",
            "process: 49.90% (2496 in 5000)\n",
            "process: 50.00% (2501 in 5000)\n",
            "process: 50.10% (2506 in 5000)\n",
            "process: 50.20% (2511 in 5000)\n",
            "process: 50.30% (2516 in 5000)\n",
            "process: 50.40% (2521 in 5000)\n",
            "process: 50.50% (2526 in 5000)\n",
            "process: 50.60% (2531 in 5000)\n",
            "process: 50.70% (2536 in 5000)\n",
            "process: 50.80% (2541 in 5000)\n",
            "process: 50.90% (2546 in 5000)\n",
            "process: 51.00% (2551 in 5000)\n",
            "process: 51.10% (2556 in 5000)\n",
            "process: 51.20% (2561 in 5000)\n",
            "process: 51.30% (2566 in 5000)\n",
            "process: 51.40% (2571 in 5000)\n",
            "process: 51.50% (2576 in 5000)\n",
            "process: 51.60% (2581 in 5000)\n",
            "process: 51.70% (2586 in 5000)\n",
            "process: 51.80% (2591 in 5000)\n",
            "process: 51.90% (2596 in 5000)\n",
            "process: 52.00% (2601 in 5000)\n",
            "process: 52.10% (2606 in 5000)\n",
            "process: 52.20% (2611 in 5000)\n",
            "process: 52.30% (2616 in 5000)\n",
            "process: 52.40% (2621 in 5000)\n",
            "process: 52.50% (2626 in 5000)\n",
            "process: 52.60% (2631 in 5000)\n",
            "process: 52.70% (2636 in 5000)\n",
            "process: 52.80% (2641 in 5000)\n",
            "process: 52.90% (2646 in 5000)\n",
            "process: 53.00% (2651 in 5000)\n",
            "process: 53.10% (2656 in 5000)\n",
            "process: 53.20% (2661 in 5000)\n",
            "process: 53.30% (2666 in 5000)\n",
            "process: 53.40% (2671 in 5000)\n",
            "process: 53.50% (2676 in 5000)\n",
            "process: 53.60% (2681 in 5000)\n",
            "process: 53.70% (2686 in 5000)\n",
            "process: 53.80% (2691 in 5000)\n",
            "process: 53.90% (2696 in 5000)\n",
            "process: 54.00% (2701 in 5000)\n",
            "process: 54.10% (2706 in 5000)\n",
            "process: 54.20% (2711 in 5000)\n",
            "process: 54.30% (2716 in 5000)\n",
            "process: 54.40% (2721 in 5000)\n",
            "process: 54.50% (2726 in 5000)\n",
            "process: 54.60% (2731 in 5000)\n",
            "process: 54.70% (2736 in 5000)\n",
            "process: 54.80% (2741 in 5000)\n",
            "process: 54.90% (2746 in 5000)\n",
            "process: 55.00% (2751 in 5000)\n",
            "process: 55.10% (2756 in 5000)\n",
            "process: 55.20% (2761 in 5000)\n",
            "process: 55.30% (2766 in 5000)\n",
            "process: 55.40% (2771 in 5000)\n",
            "process: 55.50% (2776 in 5000)\n",
            "process: 55.60% (2781 in 5000)\n",
            "process: 55.70% (2786 in 5000)\n",
            "process: 55.80% (2791 in 5000)\n",
            "process: 55.90% (2796 in 5000)\n",
            "process: 56.00% (2801 in 5000)\n",
            "process: 56.10% (2806 in 5000)\n",
            "process: 56.20% (2811 in 5000)\n",
            "process: 56.30% (2816 in 5000)\n",
            "process: 56.40% (2821 in 5000)\n",
            "process: 56.50% (2826 in 5000)\n",
            "process: 56.60% (2831 in 5000)\n",
            "process: 56.70% (2836 in 5000)\n",
            "process: 56.80% (2841 in 5000)\n",
            "process: 56.90% (2846 in 5000)\n",
            "process: 57.00% (2851 in 5000)\n",
            "process: 57.10% (2856 in 5000)\n",
            "process: 57.20% (2861 in 5000)\n",
            "process: 57.30% (2866 in 5000)\n",
            "process: 57.40% (2871 in 5000)\n",
            "process: 57.50% (2876 in 5000)\n",
            "process: 57.60% (2881 in 5000)\n",
            "process: 57.70% (2886 in 5000)\n",
            "process: 57.80% (2891 in 5000)\n",
            "process: 57.90% (2896 in 5000)\n",
            "process: 58.00% (2901 in 5000)\n",
            "process: 58.10% (2906 in 5000)\n",
            "process: 58.20% (2911 in 5000)\n",
            "process: 58.30% (2916 in 5000)\n",
            "process: 58.40% (2921 in 5000)\n",
            "process: 58.50% (2926 in 5000)\n",
            "process: 58.60% (2931 in 5000)\n",
            "process: 58.70% (2936 in 5000)\n",
            "process: 58.80% (2941 in 5000)\n",
            "process: 58.90% (2946 in 5000)\n",
            "process: 59.00% (2951 in 5000)\n",
            "process: 59.10% (2956 in 5000)\n",
            "process: 59.20% (2961 in 5000)\n",
            "process: 59.30% (2966 in 5000)\n",
            "process: 59.40% (2971 in 5000)\n",
            "process: 59.50% (2976 in 5000)\n",
            "process: 59.60% (2981 in 5000)\n",
            "process: 59.70% (2986 in 5000)\n",
            "process: 59.80% (2991 in 5000)\n",
            "process: 59.90% (2996 in 5000)\n",
            "process: 60.00% (3001 in 5000)\n",
            "process: 60.10% (3006 in 5000)\n",
            "process: 60.20% (3011 in 5000)\n",
            "process: 60.30% (3016 in 5000)\n",
            "process: 60.40% (3021 in 5000)\n",
            "process: 60.50% (3026 in 5000)\n",
            "process: 60.60% (3031 in 5000)\n",
            "process: 60.70% (3036 in 5000)\n",
            "process: 60.80% (3041 in 5000)\n",
            "process: 60.90% (3046 in 5000)\n",
            "process: 61.00% (3051 in 5000)\n",
            "process: 61.10% (3056 in 5000)\n",
            "process: 61.20% (3061 in 5000)\n",
            "process: 61.30% (3066 in 5000)\n",
            "process: 61.40% (3071 in 5000)\n",
            "process: 61.50% (3076 in 5000)\n",
            "process: 61.60% (3081 in 5000)\n",
            "process: 61.70% (3086 in 5000)\n",
            "process: 61.80% (3091 in 5000)\n",
            "process: 61.90% (3096 in 5000)\n",
            "process: 62.00% (3101 in 5000)\n",
            "process: 62.10% (3106 in 5000)\n",
            "process: 62.20% (3111 in 5000)\n",
            "process: 62.30% (3116 in 5000)\n",
            "process: 62.40% (3121 in 5000)\n",
            "process: 62.50% (3126 in 5000)\n",
            "process: 62.60% (3131 in 5000)\n",
            "process: 62.70% (3136 in 5000)\n",
            "process: 62.80% (3141 in 5000)\n",
            "process: 62.90% (3146 in 5000)\n",
            "process: 63.00% (3151 in 5000)\n",
            "process: 63.10% (3156 in 5000)\n",
            "process: 63.20% (3161 in 5000)\n",
            "process: 63.30% (3166 in 5000)\n",
            "process: 63.40% (3171 in 5000)\n",
            "process: 63.50% (3176 in 5000)\n",
            "process: 63.60% (3181 in 5000)\n",
            "process: 63.70% (3186 in 5000)\n",
            "process: 63.80% (3191 in 5000)\n",
            "process: 63.90% (3196 in 5000)\n",
            "process: 64.00% (3201 in 5000)\n",
            "process: 64.10% (3206 in 5000)\n",
            "process: 64.20% (3211 in 5000)\n",
            "process: 64.30% (3216 in 5000)\n",
            "process: 64.40% (3221 in 5000)\n",
            "process: 64.50% (3226 in 5000)\n",
            "process: 64.60% (3231 in 5000)\n",
            "process: 64.70% (3236 in 5000)\n",
            "process: 64.80% (3241 in 5000)\n",
            "process: 64.90% (3246 in 5000)\n",
            "process: 65.00% (3251 in 5000)\n",
            "process: 65.10% (3256 in 5000)\n",
            "process: 65.20% (3261 in 5000)\n",
            "process: 65.30% (3266 in 5000)\n",
            "process: 65.40% (3271 in 5000)\n",
            "process: 65.50% (3276 in 5000)\n",
            "process: 65.60% (3281 in 5000)\n",
            "process: 65.70% (3286 in 5000)\n",
            "process: 65.80% (3291 in 5000)\n",
            "process: 65.90% (3296 in 5000)\n",
            "process: 66.00% (3301 in 5000)\n",
            "process: 66.10% (3306 in 5000)\n",
            "process: 66.20% (3311 in 5000)\n",
            "process: 66.30% (3316 in 5000)\n",
            "process: 66.40% (3321 in 5000)\n",
            "process: 66.50% (3326 in 5000)\n",
            "process: 66.60% (3331 in 5000)\n",
            "process: 66.70% (3336 in 5000)\n",
            "process: 66.80% (3341 in 5000)\n",
            "process: 66.90% (3346 in 5000)\n",
            "process: 67.00% (3351 in 5000)\n",
            "process: 67.10% (3356 in 5000)\n",
            "process: 67.20% (3361 in 5000)\n",
            "process: 67.30% (3366 in 5000)\n",
            "process: 67.40% (3371 in 5000)\n",
            "process: 67.50% (3376 in 5000)\n",
            "process: 67.60% (3381 in 5000)\n",
            "process: 67.70% (3386 in 5000)\n",
            "process: 67.80% (3391 in 5000)\n",
            "process: 67.90% (3396 in 5000)\n",
            "process: 68.00% (3401 in 5000)\n",
            "process: 68.10% (3406 in 5000)\n",
            "process: 68.20% (3411 in 5000)\n",
            "process: 68.30% (3416 in 5000)\n",
            "process: 68.40% (3421 in 5000)\n",
            "process: 68.50% (3426 in 5000)\n",
            "process: 68.60% (3431 in 5000)\n",
            "process: 68.70% (3436 in 5000)\n",
            "process: 68.80% (3441 in 5000)\n",
            "process: 68.90% (3446 in 5000)\n",
            "process: 69.00% (3451 in 5000)\n",
            "process: 69.10% (3456 in 5000)\n",
            "process: 69.20% (3461 in 5000)\n",
            "process: 69.30% (3466 in 5000)\n",
            "process: 69.40% (3471 in 5000)\n",
            "process: 69.50% (3476 in 5000)\n",
            "process: 69.60% (3481 in 5000)\n",
            "process: 69.70% (3486 in 5000)\n",
            "process: 69.80% (3491 in 5000)\n",
            "process: 69.90% (3496 in 5000)\n",
            "process: 70.00% (3501 in 5000)\n",
            "process: 70.10% (3506 in 5000)\n",
            "process: 70.20% (3511 in 5000)\n",
            "process: 70.30% (3516 in 5000)\n",
            "process: 70.40% (3521 in 5000)\n",
            "process: 70.50% (3526 in 5000)\n",
            "process: 70.60% (3531 in 5000)\n",
            "process: 70.70% (3536 in 5000)\n",
            "process: 70.80% (3541 in 5000)\n",
            "process: 70.90% (3546 in 5000)\n",
            "process: 71.00% (3551 in 5000)\n",
            "process: 71.10% (3556 in 5000)\n",
            "process: 71.20% (3561 in 5000)\n",
            "process: 71.30% (3566 in 5000)\n",
            "process: 71.40% (3571 in 5000)\n",
            "process: 71.50% (3576 in 5000)\n",
            "process: 71.60% (3581 in 5000)\n",
            "process: 71.70% (3586 in 5000)\n",
            "process: 71.80% (3591 in 5000)\n",
            "process: 71.90% (3596 in 5000)\n",
            "process: 72.00% (3601 in 5000)\n",
            "process: 72.10% (3606 in 5000)\n",
            "process: 72.20% (3611 in 5000)\n",
            "process: 72.30% (3616 in 5000)\n",
            "process: 72.40% (3621 in 5000)\n",
            "process: 72.50% (3626 in 5000)\n",
            "process: 72.60% (3631 in 5000)\n",
            "process: 72.70% (3636 in 5000)\n",
            "process: 72.80% (3641 in 5000)\n",
            "process: 72.90% (3646 in 5000)\n",
            "process: 73.00% (3651 in 5000)\n",
            "process: 73.10% (3656 in 5000)\n",
            "process: 73.20% (3661 in 5000)\n",
            "process: 73.30% (3666 in 5000)\n",
            "process: 73.40% (3671 in 5000)\n",
            "process: 73.50% (3676 in 5000)\n",
            "process: 73.60% (3681 in 5000)\n",
            "process: 73.70% (3686 in 5000)\n",
            "process: 73.80% (3691 in 5000)\n",
            "process: 73.90% (3696 in 5000)\n",
            "process: 74.00% (3701 in 5000)\n",
            "process: 74.10% (3706 in 5000)\n",
            "process: 74.20% (3711 in 5000)\n",
            "process: 74.30% (3716 in 5000)\n",
            "process: 74.40% (3721 in 5000)\n",
            "process: 74.50% (3726 in 5000)\n",
            "process: 74.60% (3731 in 5000)\n",
            "process: 74.70% (3736 in 5000)\n",
            "process: 74.80% (3741 in 5000)\n",
            "process: 74.90% (3746 in 5000)\n",
            "process: 75.00% (3751 in 5000)\n",
            "process: 75.10% (3756 in 5000)\n",
            "process: 75.20% (3761 in 5000)\n",
            "process: 75.30% (3766 in 5000)\n",
            "process: 75.40% (3771 in 5000)\n",
            "process: 75.50% (3776 in 5000)\n",
            "process: 75.60% (3781 in 5000)\n",
            "process: 75.70% (3786 in 5000)\n",
            "process: 75.80% (3791 in 5000)\n",
            "process: 75.90% (3796 in 5000)\n",
            "process: 76.00% (3801 in 5000)\n",
            "process: 76.10% (3806 in 5000)\n",
            "process: 76.20% (3811 in 5000)\n",
            "process: 76.30% (3816 in 5000)\n",
            "process: 76.40% (3821 in 5000)\n",
            "process: 76.50% (3826 in 5000)\n",
            "process: 76.60% (3831 in 5000)\n",
            "process: 76.70% (3836 in 5000)\n",
            "process: 76.80% (3841 in 5000)\n",
            "process: 76.90% (3846 in 5000)\n",
            "process: 77.00% (3851 in 5000)\n",
            "process: 77.10% (3856 in 5000)\n",
            "process: 77.20% (3861 in 5000)\n",
            "process: 77.30% (3866 in 5000)\n",
            "process: 77.40% (3871 in 5000)\n",
            "process: 77.50% (3876 in 5000)\n",
            "process: 77.60% (3881 in 5000)\n",
            "process: 77.70% (3886 in 5000)\n",
            "process: 77.80% (3891 in 5000)\n",
            "process: 77.90% (3896 in 5000)\n",
            "process: 78.00% (3901 in 5000)\n",
            "process: 78.10% (3906 in 5000)\n",
            "process: 78.20% (3911 in 5000)\n",
            "process: 78.30% (3916 in 5000)\n",
            "process: 78.40% (3921 in 5000)\n",
            "process: 78.50% (3926 in 5000)\n",
            "process: 78.60% (3931 in 5000)\n",
            "process: 78.70% (3936 in 5000)\n",
            "process: 78.80% (3941 in 5000)\n",
            "process: 78.90% (3946 in 5000)\n",
            "process: 79.00% (3951 in 5000)\n",
            "process: 79.10% (3956 in 5000)\n",
            "process: 79.20% (3961 in 5000)\n",
            "process: 79.30% (3966 in 5000)\n",
            "process: 79.40% (3971 in 5000)\n",
            "process: 79.50% (3976 in 5000)\n",
            "process: 79.60% (3981 in 5000)\n",
            "process: 79.70% (3986 in 5000)\n",
            "process: 79.80% (3991 in 5000)\n",
            "process: 79.90% (3996 in 5000)\n",
            "process: 80.00% (4001 in 5000)\n",
            "process: 80.10% (4006 in 5000)\n",
            "process: 80.20% (4011 in 5000)\n",
            "process: 80.30% (4016 in 5000)\n",
            "process: 80.40% (4021 in 5000)\n",
            "process: 80.50% (4026 in 5000)\n",
            "process: 80.60% (4031 in 5000)\n",
            "process: 80.70% (4036 in 5000)\n",
            "process: 80.80% (4041 in 5000)\n",
            "process: 80.90% (4046 in 5000)\n",
            "process: 81.00% (4051 in 5000)\n",
            "process: 81.10% (4056 in 5000)\n",
            "process: 81.20% (4061 in 5000)\n",
            "process: 81.30% (4066 in 5000)\n",
            "process: 81.40% (4071 in 5000)\n",
            "process: 81.50% (4076 in 5000)\n",
            "process: 81.60% (4081 in 5000)\n",
            "process: 81.70% (4086 in 5000)\n",
            "process: 81.80% (4091 in 5000)\n",
            "process: 81.90% (4096 in 5000)\n",
            "process: 82.00% (4101 in 5000)\n",
            "process: 82.10% (4106 in 5000)\n",
            "process: 82.20% (4111 in 5000)\n",
            "process: 82.30% (4116 in 5000)\n",
            "process: 82.40% (4121 in 5000)\n",
            "process: 82.50% (4126 in 5000)\n",
            "process: 82.60% (4131 in 5000)\n",
            "process: 82.70% (4136 in 5000)\n",
            "process: 82.80% (4141 in 5000)\n",
            "process: 82.90% (4146 in 5000)\n",
            "process: 83.00% (4151 in 5000)\n",
            "process: 83.10% (4156 in 5000)\n",
            "process: 83.20% (4161 in 5000)\n",
            "process: 83.30% (4166 in 5000)\n",
            "process: 83.40% (4171 in 5000)\n",
            "process: 83.50% (4176 in 5000)\n",
            "process: 83.60% (4181 in 5000)\n",
            "process: 83.70% (4186 in 5000)\n",
            "process: 83.80% (4191 in 5000)\n",
            "process: 83.90% (4196 in 5000)\n",
            "process: 84.00% (4201 in 5000)\n",
            "process: 84.10% (4206 in 5000)\n",
            "process: 84.20% (4211 in 5000)\n",
            "process: 84.30% (4216 in 5000)\n",
            "process: 84.40% (4221 in 5000)\n",
            "process: 84.50% (4226 in 5000)\n",
            "process: 84.60% (4231 in 5000)\n",
            "process: 84.70% (4236 in 5000)\n",
            "process: 84.80% (4241 in 5000)\n",
            "process: 84.90% (4246 in 5000)\n",
            "process: 85.00% (4251 in 5000)\n",
            "process: 85.10% (4256 in 5000)\n",
            "process: 85.20% (4261 in 5000)\n",
            "process: 85.30% (4266 in 5000)\n",
            "process: 85.40% (4271 in 5000)\n",
            "process: 85.50% (4276 in 5000)\n",
            "process: 85.60% (4281 in 5000)\n",
            "process: 85.70% (4286 in 5000)\n",
            "process: 85.80% (4291 in 5000)\n",
            "process: 85.90% (4296 in 5000)\n",
            "process: 86.00% (4301 in 5000)\n",
            "process: 86.10% (4306 in 5000)\n",
            "process: 86.20% (4311 in 5000)\n",
            "process: 86.30% (4316 in 5000)\n",
            "process: 86.40% (4321 in 5000)\n",
            "process: 86.50% (4326 in 5000)\n",
            "process: 86.60% (4331 in 5000)\n",
            "process: 86.70% (4336 in 5000)\n",
            "process: 86.80% (4341 in 5000)\n",
            "process: 86.90% (4346 in 5000)\n",
            "process: 87.00% (4351 in 5000)\n",
            "process: 87.10% (4356 in 5000)\n",
            "process: 87.20% (4361 in 5000)\n",
            "process: 87.30% (4366 in 5000)\n",
            "process: 87.40% (4371 in 5000)\n",
            "process: 87.50% (4376 in 5000)\n",
            "process: 87.60% (4381 in 5000)\n",
            "process: 87.70% (4386 in 5000)\n",
            "process: 87.80% (4391 in 5000)\n",
            "process: 87.90% (4396 in 5000)\n",
            "process: 88.00% (4401 in 5000)\n",
            "process: 88.10% (4406 in 5000)\n",
            "process: 88.20% (4411 in 5000)\n",
            "process: 88.30% (4416 in 5000)\n",
            "process: 88.40% (4421 in 5000)\n",
            "process: 88.50% (4426 in 5000)\n",
            "process: 88.60% (4431 in 5000)\n",
            "process: 88.70% (4436 in 5000)\n",
            "process: 88.80% (4441 in 5000)\n",
            "process: 88.90% (4446 in 5000)\n",
            "process: 89.00% (4451 in 5000)\n",
            "process: 89.10% (4456 in 5000)\n",
            "process: 89.20% (4461 in 5000)\n",
            "process: 89.30% (4466 in 5000)\n",
            "process: 89.40% (4471 in 5000)\n",
            "process: 89.50% (4476 in 5000)\n",
            "process: 89.60% (4481 in 5000)\n",
            "process: 89.70% (4486 in 5000)\n",
            "process: 89.80% (4491 in 5000)\n",
            "process: 89.90% (4496 in 5000)\n",
            "process: 90.00% (4501 in 5000)\n",
            "process: 90.10% (4506 in 5000)\n",
            "process: 90.20% (4511 in 5000)\n",
            "process: 90.30% (4516 in 5000)\n",
            "process: 90.40% (4521 in 5000)\n",
            "process: 90.50% (4526 in 5000)\n",
            "process: 90.60% (4531 in 5000)\n",
            "process: 90.70% (4536 in 5000)\n",
            "process: 90.80% (4541 in 5000)\n",
            "process: 90.90% (4546 in 5000)\n",
            "process: 91.00% (4551 in 5000)\n",
            "process: 91.10% (4556 in 5000)\n",
            "process: 91.20% (4561 in 5000)\n",
            "process: 91.30% (4566 in 5000)\n",
            "process: 91.40% (4571 in 5000)\n",
            "process: 91.50% (4576 in 5000)\n",
            "process: 91.60% (4581 in 5000)\n",
            "process: 91.70% (4586 in 5000)\n",
            "process: 91.80% (4591 in 5000)\n",
            "process: 91.90% (4596 in 5000)\n",
            "process: 92.00% (4601 in 5000)\n",
            "process: 92.10% (4606 in 5000)\n",
            "process: 92.20% (4611 in 5000)\n",
            "process: 92.30% (4616 in 5000)\n",
            "process: 92.40% (4621 in 5000)\n",
            "process: 92.50% (4626 in 5000)\n",
            "process: 92.60% (4631 in 5000)\n",
            "process: 92.70% (4636 in 5000)\n",
            "process: 92.80% (4641 in 5000)\n",
            "process: 92.90% (4646 in 5000)\n",
            "process: 93.00% (4651 in 5000)\n",
            "process: 93.10% (4656 in 5000)\n",
            "process: 93.20% (4661 in 5000)\n",
            "process: 93.30% (4666 in 5000)\n",
            "process: 93.40% (4671 in 5000)\n",
            "process: 93.50% (4676 in 5000)\n",
            "process: 93.60% (4681 in 5000)\n",
            "process: 93.70% (4686 in 5000)\n",
            "process: 93.80% (4691 in 5000)\n",
            "process: 93.90% (4696 in 5000)\n",
            "process: 94.00% (4701 in 5000)\n",
            "process: 94.10% (4706 in 5000)\n",
            "process: 94.20% (4711 in 5000)\n",
            "process: 94.30% (4716 in 5000)\n",
            "process: 94.40% (4721 in 5000)\n",
            "process: 94.50% (4726 in 5000)\n",
            "process: 94.60% (4731 in 5000)\n",
            "process: 94.70% (4736 in 5000)\n",
            "process: 94.80% (4741 in 5000)\n",
            "process: 94.90% (4746 in 5000)\n",
            "process: 95.00% (4751 in 5000)\n",
            "process: 95.10% (4756 in 5000)\n",
            "process: 95.20% (4761 in 5000)\n",
            "process: 95.30% (4766 in 5000)\n",
            "process: 95.40% (4771 in 5000)\n",
            "process: 95.50% (4776 in 5000)\n",
            "process: 95.60% (4781 in 5000)\n",
            "process: 95.70% (4786 in 5000)\n",
            "process: 95.80% (4791 in 5000)\n",
            "process: 95.90% (4796 in 5000)\n",
            "process: 96.00% (4801 in 5000)\n",
            "process: 96.10% (4806 in 5000)\n",
            "process: 96.20% (4811 in 5000)\n",
            "process: 96.30% (4816 in 5000)\n",
            "process: 96.40% (4821 in 5000)\n",
            "process: 96.50% (4826 in 5000)\n",
            "process: 96.60% (4831 in 5000)\n",
            "process: 96.70% (4836 in 5000)\n",
            "process: 96.80% (4841 in 5000)\n",
            "process: 96.90% (4846 in 5000)\n",
            "process: 97.00% (4851 in 5000)\n",
            "process: 97.10% (4856 in 5000)\n",
            "process: 97.20% (4861 in 5000)\n",
            "process: 97.30% (4866 in 5000)\n",
            "process: 97.40% (4871 in 5000)\n",
            "process: 97.50% (4876 in 5000)\n",
            "process: 97.60% (4881 in 5000)\n",
            "process: 97.70% (4886 in 5000)\n",
            "process: 97.80% (4891 in 5000)\n",
            "process: 97.90% (4896 in 5000)\n",
            "process: 98.00% (4901 in 5000)\n",
            "process: 98.10% (4906 in 5000)\n",
            "process: 98.20% (4911 in 5000)\n",
            "process: 98.30% (4916 in 5000)\n",
            "process: 98.40% (4921 in 5000)\n",
            "process: 98.50% (4926 in 5000)\n",
            "process: 98.60% (4931 in 5000)\n",
            "process: 98.70% (4936 in 5000)\n",
            "process: 98.80% (4941 in 5000)\n",
            "process: 98.90% (4946 in 5000)\n",
            "process: 99.00% (4951 in 5000)\n",
            "process: 99.10% (4956 in 5000)\n",
            "process: 99.20% (4961 in 5000)\n",
            "process: 99.30% (4966 in 5000)\n",
            "process: 99.40% (4971 in 5000)\n",
            "process: 99.50% (4976 in 5000)\n",
            "process: 99.60% (4981 in 5000)\n",
            "process: 99.70% (4986 in 5000)\n",
            "process: 99.80% (4991 in 5000)\n",
            "process: 99.90% (4996 in 5000)\n",
            "5000 Save successfully.\n",
            "process: 100.00% (5000 in 5000)\n",
            "Save successfully. Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpObSK3XSNHw"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}